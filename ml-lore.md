The second argues that small batches cause gradient descent to attract to wider basins, while large
batches cause gradient descent to attract to narrow basins, which causes higher error when attempting
to generalize, because missing the mark in a narrow basin causes higher changes in error.

