{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "\n",
    "from leaf.dta import LeafDataset, GetPatches, TransformPatches, RandomGreen, LeafDataLoader\n",
    "from leaf.model import LeafModel, train_one_epoch, validate_one_epoch, warmup\n",
    "\n",
    "\n",
    "# Transforms with normalizations for imagenet\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        RandomGreen(224, 224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'warmup': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        RandomGreen(224, 224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'patches': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"/mnt/hdd/leaf-disease-outputs\")\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "logging_dir = Path(\"/mnt/hdd/leaf-disease-runs\")\n",
    "logging_dir.mkdir(exist_ok=True)\n",
    "\n",
    "batch_size = 16\n",
    "val_batch_size = 32\n",
    "\n",
    "num_workers = 4\n",
    "\n",
    "learning_rate = 1e-4\n",
    "#min_learning_rate = 1e-6\n",
    "weight_decay = 1e-6\n",
    "warmup_lr = 1e-7\n",
    "\n",
    "#T_0 = 10\n",
    "\n",
    "patches_logging_steps = 1000\n",
    "save_checkpoints = True\n",
    "\n",
    "train_dset = LeafDataset(\"./data/train_images\", \"./data/train_images/labels.csv\", transform=data_transforms[\"train\"])\n",
    "patches_dset = LeafDataset(\"./data/patches_train\", \"./data/patches_train/labels.csv\", extended_labels=True, transform=data_transforms[\"patches\"])\n",
    "warmup_dset = LeafDataset(\"./data/train_images\", \"./data/train_images/labels.csv\", transform=data_transforms[\"warmup\"])\n",
    "val_dset = LeafDataset(\"./data/patches_val\", \"./data/patches_val/labels.csv\", extended_labels=True, transform=data_transforms[\"val\"])\n",
    "\n",
    "train_dataloader = LeafDataLoader(train_dset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "patches_dataloader = LeafDataLoader(patches_dset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_dataloader = LeafDataLoader(val_dset, batch_size=val_batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "leaf_model = LeafModel(\"tf_efficientnet_b4_ns\", model_prefix=\"MONEVE\", save_dir=save_dir, logging_dir=logging_dir)\n",
    "\n",
    "# optimizer = Adam(leaf_model.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer = Adam(leaf_model.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = None\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=1, eta_min=min_learning_rate, last_epoch=-1)\n",
    "leaf_model.update_optimizer_scheduler(optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup(leaf_model, train_dataloader, 500, warmup_lr, log_warmup=True)\n",
    "train_one_epoch(leaf_model, patches_dataloader, log_steps=patches_logging_steps, val_data_loader=val_dataloader, save_at_log_steps=save_checkpoints, epoch_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = validate_one_epoch(leaf_model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_model.save_checkpoint(\"MONEVE_epoch_1\", optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_model.optimizer.param_groups[0]['lr'] = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_epoch(leaf_model, patches_dataloader, log_steps=patches_logging_steps, val_data_loader=val_dataloader, save_at_log_steps=save_checkpoints, epoch_name=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = validate_one_epoch(leaf_model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_model.save_checkpoint(\"MONEVE_epoch_2\", optimizer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_model.optimizer.param_groups[0]['lr'] = 1e-5\n",
    "leaf_model.load_checkpoint(\"MONEVE_epoch_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_model.model = leaf_model.model.to(leaf_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = validate_one_epoch(leaf_model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = leaf_model.model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_original_fnames = np.array(val_dset.original_fnames)\n",
    "np_fnames = np.array(val_dset.fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits_all = torch.zeros((val_dataloader.num_padded_samples, 5), dtype=float, device=leaf_model.device)\n",
    "    labels_all = torch.zeros((val_dataloader.num_padded_samples), dtype=int, device=leaf_model.device)\n",
    "    original_fnames = np.array([\"\"] * val_dataloader.num_padded_samples, dtype=np.dtype(\"U22\"))\n",
    "    patch_idxs = np.zeros((val_dataloader.num_padded_samples,), dtype=int)\n",
    "    i = 0\n",
    "    for imgs, labels, idxs in tqdm(val_dataloader):\n",
    "        imgs = imgs.to(leaf_model.device)\n",
    "        labels = labels.to(leaf_model.device)\n",
    "        bs = imgs.shape[0]\n",
    "        logits_all[i:(i + bs), :] = leaf_model.model.forward(imgs)\n",
    "        labels_all[i:(i + bs)] = labels\n",
    "        original_fnames[i:(i + bs)] = np_original_fnames[idxs]\n",
    "        patch_idxs[i:(i + bs)] = np.array([int(val_dset.fnames[idx][-7:][:3]) for idx in idxs])\n",
    "        i += bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():    \n",
    "    val_loss = leaf_model.loss_fn(logits_all, labels_all)\n",
    "    preds_all = logits_all.argmax(axis=-1)\n",
    "    val_acc = (labels_all == preds_all).sum().item() / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_fnames[original_fnames == \"\"] = \"-1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_all.cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    \"img_id\": np.array([int(fname[:-4]) for fname in original_fnames]).astype(int),\n",
    "    \"patch_idx\": patch_idxs.astype(int),\n",
    "    \"label\": labels_all.cpu().numpy().astype(int),\n",
    "    \"logits_0\": logits_all.cpu().numpy()[:,0],\n",
    "    \"logits_1\": logits_all.cpu().numpy()[:,1],\n",
    "    \"logits_2\": logits_all.cpu().numpy()[:,2],\n",
    "    \"logits_3\": logits_all.cpu().numpy()[:,3],\n",
    "    \"logits_4\": logits_all.cpu().numpy()[:,4],\n",
    "    \"pred\": preds_all.cpu().numpy().astype(int)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_df(label):\n",
    "    return f1_score(pred_df[\"label\"] == label, pred_df[\"pred\"] == label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = pred_df.groupby(\"img_id\").agg({\"label\": \"first\", \"logits_0\": \"mean\", \"logits_1\": \"mean\", \"logits_2\": \"mean\",\"logits_3\": \"mean\", \"logits_4\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = img_df.loc[img_df.index != -1, :].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_preds = img_df.loc[:, [\"logits_0\", \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\"]].values.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df[\"pred\"] = img_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = img_df.loc[:, [\"img_id\", \"label\", \"pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_df[\"label\"] == img_df[\"pred\"]).sum() / img_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_234 = img_df.loc[img_df[\"label\"].isin([2, 3, 4]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(only_234[\"label\"] == only_234[\"pred\"]).sum() / only_234.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_0234 = img_df.loc[img_df[\"label\"].isin([0, 2, 3, 4]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(only_0234[\"label\"] == only_0234[\"pred\"]).sum() / only_0234.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_one_hot(pred):\n",
    "    vals = np.arange(5)\n",
    "    assert pred in vals\n",
    "    return (vals == pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_aug = pd.concat([pred_df, pd.DataFrame(np.array([pred_to_one_hot(pred) for pred in pred_df[\"pred\"]]))], axis=1).rename(columns={i: f\"pred_{i}\" for i in range(5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_aug = pred_df_aug.loc[pred_df[\"img_id\"] != -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = pred_df_aug.groupby(\"img_id\").agg({**{\"label\": \"first\", \"patch_idx\": \"max\"},\n",
    "                                        **{f\"logits_{i}\": \"mean\" for i in range(5)},\n",
    "                                        **{f\"pred_{i}\": \"sum\" for i in range(5)}}).reset_index().rename(columns={\"patch_idx\": \"n_patches\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df[img_df[\"label\"] == 0].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df_mod = pd.concat([img_df,\n",
    "           pd.DataFrame(np.apply_along_axis(softmax, 1, img_df.loc[:, [\"logits_0\", \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\"]].values)).rename(columns = {i: f\"prob_{i}\" for i in range(5)})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df_mod.loc[img_df_mod[\"label\"] == 1, :].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grid = 10\n",
    "max_bonus = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(mod_probs):\n",
    "    return (img_df_mod[\"label\"].values == mod_probs.argmax(axis=1)).sum() / img_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc(img_df_mod.loc[:, [f\"prob_{i}\" for i in range(5)]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pbar = tqdm(total = max_bonus ** 5)\n",
    "best_combo = None\n",
    "best_acc = -1\n",
    "for bonus_0 in np.linspace(0, max_bonus, n_grid+1):\n",
    "    for bonus_1 in np.linspace(0, max_bonus, n_grid+1):\n",
    "        for bonus_2 in np.linspace(0, max_bonus, n_grid+1):\n",
    "            for bonus_3 in np.linspace(0, max_bonus, n_grid+1):\n",
    "                for bonus_4 in np.linspace(0, max_bonus, n_grid+1):\n",
    "                    mod_probs = img_df_mod.loc[:, [f\"prob_{i}\" for i in range(5)]].values\n",
    "                    mod_probs[:, 0] += bonus_0\n",
    "                    mod_probs[:, 1] += bonus_1\n",
    "                    mod_probs[:, 2] += bonus_2\n",
    "                    mod_probs[:, 3] += bonus_3\n",
    "                    mod_probs[:, 4] += bonus_4\n",
    "                    acc = get_acc(mod_probs)\n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        best_combo = (bonus_0, bonus_1)\n",
    "                    #pbar.update(1)\n",
    "#pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df_svm = img_df_mod.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df_svm[\"n_patches\"] = img_df_svm[\"n_patches\"] / img_df_svm[\"n_patches\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    img_df_svm[f\"pred_{i}\"] = img_df_svm[f\"pred_{i}\"] / 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df_svm = img_df_svm.drop(columns = [f\"logits_{i}\" for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = img_df_svm.iloc[:, 2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = img_df_svm[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = idxs[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idxs = idxs[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[train_idxs, :], y[train_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = X[test_idxs, :], y[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=5, kernel=\"rbf\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((clf.predict(X_test) == y_test)) / X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'multi:softmax', \"num_class\":5}\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 1\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_pred == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant: softmax, then mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = pd.concat([pred_df.loc[:, [\"img_id\", \"patch_idx\", \"label\"]],\n",
    "           pd.DataFrame(np.apply_along_axis(softmax, 1, pred_df.loc[:, [\"logits_0\", \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\"]].values))], axis=1)\n",
    "img_df.rename(columns = {i: f\"prob_{i}\" for i in range(5)}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_preds = img_df.loc[:, [f\"prob_{i}\" for i in range(5)]].values.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df[\"pred\"] = img_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = img_df.loc[:, [\"img_id\", \"label\", \"pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_df[\"label\"] == img_df[\"pred\"]).sum() / img_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_along_axis(softmax, 1, pred_df.loc[:, [\"logits_0\", \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\"]].values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = pred_df.groupby(\"img_id\").agg({\"label\": \"first\", \"logits_0\": \"mean\", \"logits_1\": \"mean\", \"logits_2\": \"mean\",\"logits_3\": \"mean\", \"logits_4\": \"mean\",}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df(0), f1_df(1), f1_df(2), f1_df(3), f1_df(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(pred_df[\"label\"] == 1normalize=ed_df[\"pred\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_2 = pred_df.loc[pred_df[\"label\"] == 2].copy()\n",
    "(only_2[\"pred\"] == 2).sum() / only_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_1 = pred_df.loc[pred_df[\"label\"] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(only_1[\"pred\"] == 1).sum() / only_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_3 = pred_df.loc[pred_df[\"label\"] == 3].copy()\n",
    "(only_3[\"pred\"] == 3).sum() / only_3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_4 = pred_df.loc[pred_df[\"label\"] == 4].copy()\n",
    "(only_4[\"pred\"] == 4).sum() / only_4.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_0 = pred_df.loc[pred_df[\"label\"] == 0].copy()\n",
    "(only_0[\"pred\"] == 0).sum() / only_0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_fnames[-33:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'1003218714.jpg-002.jpg'[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dset.fnames[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dset.original_fnames[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        imgs = imgs.to(leaf_model.device)\n",
    "        labels = labels.to(leaf_model.device)\n",
    "        bs = imgs.shape[0]\n",
    "        logits_all[i:(i + bs), :] = leaf_model.model.forward(imgs)\n",
    "        labels_all[i:(i + bs)] = labels\n",
    "        i += bs\n",
    "\n",
    "    val_loss = leaf_model.loss_fn(logits_all, labels_all)\n",
    "    preds_all = logits_all.argmax(axis=-1)\n",
    "    val_acc = (labels_all == preds_all).sum().item() / i\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = validate_one_epoch(leaf_model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits_all = torch.zeros((val_dataloader.num_padded_samples, 5), dtype=float, device=leaf_model.device)\n",
    "    labels_all = torch.zeros((val_dataloader.num_padded_samples), dtype=int, device=leaf_model.device)\n",
    "    i = 0\n",
    "    for imgs, labels in tqdm(val_dataloader):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    imgs = imgs.to(leaf_model.device)\n",
    "    logits = leaf_model.model.forward(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logits.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
